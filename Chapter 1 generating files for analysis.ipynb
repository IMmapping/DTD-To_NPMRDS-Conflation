{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This excercise demonstrates a method to conflate real-time speed attributes from the National Performance Management Research Dataset to the Colorado DOT's modeling network. In this first chapter, the files necesarry for the conflation will be created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell is used to import necessary modules and set the directy for the output of files. If the output directory (\\\\Data) doesn't already exist, this directory will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this process will use arcpy to determine the sameness of two networks\n",
    "import arcpy as ap\n",
    "\n",
    "# the csv module is used at the end of this process to write tables to csv\n",
    "import csv\n",
    "\n",
    "# the os module is also used in this process, specifically to determine the project location\n",
    "import os\n",
    "\n",
    "# shapefile of the tmc network, from the National Performance Management Research Dataset\n",
    "tmc_network_file = os.getcwd() + '\\\\Colorado.shp'\n",
    "    \n",
    "\n",
    "# shapefile of the Colorado DOT's modeling network \n",
    "dtd_network_file = os.getcwd() + '\\\\CDOT_Network_2015_HwyLinks.shp'\n",
    "\n",
    "# the project path is set to be the location of this file\n",
    "path_of_project = os.getcwd()\n",
    "\n",
    "# and the directory for data is a directory called Data in the project directory\n",
    "path_to_data = path_of_project + '//Data//'\n",
    "\n",
    "# if the directory for the data hasn't been created\n",
    "if not os.path.exists(path_to_data):\n",
    "    # it will be created\n",
    "    os.makedirs(path_to_data)\n",
    "\n",
    "# arcpy has a workplace parameter that sets the output to the data directory\n",
    "ap.env.workspace = path_to_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primary point of comparison of these models will be the lines' bearing, so in the following cell bearing will be added as an attribute to each network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate the the list of network files\n",
    "for each in [tmc_network_file, dtd_network_file]:\n",
    "    \n",
    "    # and try to add the bearing attribute\n",
    "    try:\n",
    "        ap.AddGeometryAttributes_management(each, 'LINE_BEARING')\n",
    "    # if not possible, then just pass\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to consider many points along a line, while potentially overkill, this conflation methodolgy uses points every 50 Meters along each segment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # generate points every 50 meters along the tmc network, excluding the end points\n",
    "    ap.GeneratePointsAlongLines_management(tmc_network_file, \n",
    "                                       path_to_data + 'tmc_network_points.shp', \n",
    "                                       'DISTANCE', \n",
    "                                       '50 Meters',\n",
    "                                       '', \n",
    "                                       'NO_END_POINTS' )\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step will be to consider the proximity of the points along the TMC segments in relation to the modeling network. The following cell creates a table that describes the closest point on the modeling network to the points on the TMC network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # generate a table describing the proximity of points every 50 Meters along tmc network in relation the modeling network\n",
    "    # this table incudes the three closest points along the modeling network within 75 Meters of the tmc network\n",
    "    # it includes the tmc point and the closest points along the modeling network as well as the bearing\n",
    "    # and distance of between the points\n",
    "    ap.GenerateNearTable_analysis(path_to_data + 'tmc_network_points.shp', \n",
    "                              dtd_network_file,\n",
    "                              path_to_data + 'tmc_points_every_50M_near_dtd_network.dbf',\n",
    "                              '75 Meters',\n",
    "                              'LOCATION',\n",
    "                              'ANGLE',\n",
    "                              'ALL',\n",
    "                               3,\n",
    "                              'GEODESIC')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above creates a relationship between the points on the tmc network to the modeling network. The following cell relates the tmc points back to the tmc network using the 'ORIG_FID' field that is created when the points are tmc network points are created. This is accomplished using a dictionary, which stores the association between the point and the segment and a couple cursors. The first cursor is used to populate the dictionary, and the second retrieves the dictionary values and updates the TMC near table with the id of the tmc segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary object called line_id_dict\n",
    "line_id_dict = {}\n",
    "\n",
    "# establish a cursor object to iterate through the tmc network points, returning the fid of the point and the ORIG_FID, \n",
    "# ORIG_FID represents the FID of the line segment the point was derived from\n",
    "with ap.da.SearchCursor(path_to_data + 'tmc_network_points.shp', ['FID', 'ORIG_FID']) as sc:\n",
    "    for row in sc:\n",
    "        line_id_dict[row[0]] = row[1]\n",
    "\n",
    "# add a field to the near table to store the original line segment id\n",
    "ap.AddField_management(path_to_data + 'tmc_points_every_50M_near_dtd_network.dbf', 'LINE_ID', 'SHORT')\n",
    "\n",
    "# create a cursor to iterate through the near table and update the original line segment id in the near table\n",
    "with ap.da.UpdateCursor(path_to_data + 'tmc_points_every_50M_near_dtd_network.dbf',\n",
    "                       ['IN_FID', 'LINE_ID']) as uc:\n",
    "    for row in uc:\n",
    "        new_row = row\n",
    "        # assign the original segment id based on the values stored in the line_id_dictionary\n",
    "        new_row[1] = line_id_dict[row[0]]\n",
    "        uc.updateRow(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a csv file to write the near table to, this will allow the table to be accessed with non-prorietary software\n",
    "with open(path_to_data + 'matches.csv', 'wb') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    \n",
    "    # write the header to the csv file\n",
    "    writer.writerow(['match_id',\n",
    "                     'tmc_id', \n",
    "                     'dtd_id', \n",
    "                     'distance',\n",
    "                     'NEAR_RANK',\n",
    "                     'NEAR_ANGLE', \n",
    "                     'FROM_X', \n",
    "                     'FROM_Y', \n",
    "                     'NEAR_X', \n",
    "                     'NEAR_Y'])\n",
    "    \n",
    "    # establish a search cursor to iterate through matches\n",
    "    with ap.da.SearchCursor(path_to_data + 'tmc_points_every_50M_near_dtd_network.dbf', \n",
    "                             ['OID',\n",
    "                             'LINE_ID', \n",
    "                             'NEAR_FID', \n",
    "                             'NEAR_DIST',\n",
    "                             'NEAR_RANK',\n",
    "                             'NEAR_ANGLE',\n",
    "                             'FROM_X',\n",
    "                             'FROM_Y',\n",
    "                             'NEAR_X',\n",
    "                             'NEAR_Y']) as sc:\n",
    "        # for each row in the cursor\n",
    "        for row in sc:\n",
    "            # write the row to the csv file\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a csv file to writer the tmc network attributes to\n",
    "with open(path_to_data + 'tmc_attributes.csv', 'wb') as csvfile:\n",
    "    \n",
    "    # create an object to write to the csvfile\n",
    "    writer = csv.writer(csvfile)\n",
    "    \n",
    "    # write the header row\n",
    "    writer.writerow(['tmc_id', 'tmc_name', 'tmc_bearing', 'TMC', 'tmc_direction', 'tmc_type'])\n",
    "    \n",
    "    # iterate through the tmc network file\n",
    "    with ap.da.SearchCursor (tmc_network_file, ['FID', 'RoadName', 'BEARING', 'TMC', 'N_or_P', 'F_type']) as sc:\n",
    "        \n",
    "        for row in sc:\n",
    "            # store the attributes in the correct data type\n",
    "            fid = row[0]\n",
    "            name = row[1].encode('utf')\n",
    "            bearing = round(row[2],2)\n",
    "           \n",
    "            tmc = row[3]\n",
    "            direction = row[4]\n",
    "            tmc_type = row[5]\n",
    "            \n",
    "            # write the row to the csv file\n",
    "            writer.writerow([fid, name, bearing, tmc, direction, tmc_type ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a csv file to writer the modeling network attributes to\n",
    "with open(path_to_data + 'dtd_attributes.csv', 'wb') as csvfile:\n",
    "    \n",
    "    # create an object to write to the csvfile\n",
    "    writer = csv.writer(csvfile)\n",
    "    \n",
    "    # write the header row\n",
    "    writer.writerow(['dtd_id', 'dtd_name', 'dtd_type','dtd_bearing', 'dtd_one_way'])\n",
    "    \n",
    "    # iterate through the modeling network file\n",
    "    with ap.da.SearchCursor (dtd_network_file, ['FID', 'ROUTE', 'FACILITY_T', 'BEARING', 'DIR']) as sc:\n",
    "        \n",
    "        for row in sc:\n",
    "            \n",
    "            # store all the attributes in the correct data type\n",
    "            fid = row[0]\n",
    "            name = row[1].encode('utf')\n",
    "    \n",
    "            fclass = row[2]\n",
    "            bearing = round(row[3],2)\n",
    "            \n",
    "            if row[4] == 1:\n",
    "                one_way = 'N'\n",
    "            else:\n",
    "                one_way = 'Y'\n",
    "                \n",
    "            # write the row to the csv file\n",
    "            writer.writerow([fid, name, fclass, bearing, one_way])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'C:\\\\Users\\\\mcintyrei\\\\Desktop\\\\Definitely\\\\Here TMC to DTD Conflation//Data//tmc_to_dtd_match_lines.shp'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a line feature class based on the matches.csv, this can be used to demonstrate all of the \n",
    "ap.XYToLine_management(path_to_data + 'matches.csv', \n",
    "                         path_to_data + 'tmc_to_dtd_match_lines.shp',\n",
    "                         'FROM_X',\n",
    "                         'FROM_Y',\n",
    "                         'NEAR_X',\n",
    "                         'NEAR_Y',\n",
    "                         'GEODESIC',\n",
    "                         'match_id')\n",
    "\n",
    "ap.AddGeometryAttributes_management(path_to_data + 'tmc_to_dtd_match_lines.shp', 'LENGTH_GEODESIC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next level of analysis will consider only the divided highways. It's simple to determine these segments based on their attributes, but this is not always accurate. However, this will not be addressed until we are done with thie initial analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:arc1051]",
   "language": "python",
   "name": "conda-env-arc1051-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
